{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Employer Review About Their Organisation**\n\n\n**Context**\n\nEvery organization has their pros and cons which their employees feel that it should be made public so that other people who wants to join this organization make decisions based on reviews from the people.\n\n\n**Content**\n\nThis is a textual data in the form of json file. Its has more than 145k records. Each record has attributes such as\n\nReview Title\nReview Body\nReview Rating\nReviewed Company\nReview description\nAcknowledgements\nAll thanks to indeed.com to make this data public and easily available.\n\n\n**Tasks**\n\nYou task would be to predict the rating/predict the text is positive or negative whether based on the review text. Also do some analysis of the text to get some insights and trends based on individual company/organization.","metadata":{}},{"cell_type":"markdown","source":"Dataset was trained with 45% of random sample size on Google Colab. Please go further with full dataset using this notebook, if you have the resources.\n\n**Github Repository:**","metadata":{}},{"cell_type":"markdown","source":"# Download dataset from Kaggle","metadata":{"id":"ISBWr7ayaoQi"}},{"cell_type":"code","source":"! pip install -q kaggle\nfrom google.colab import files\nfiles.upload()\n! mkdir ~/.kaggle\n! cp kaggle.json ~/.kaggle/\n! chmod 600 ~/.kaggle/kaggle.json\n! kaggle datasets list\n! kaggle datasets download -d muhammedabdulazeem/employer-review-about-their-organization\n! unzip employer-review-about-their-organization.zip\nfrom google.colab import drive\ndrive.mount('/content/drive/')","metadata":{"id":"W9hLfBijZnPm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{"id":"QesgRHWPXGMr"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nimport os\nfrom datetime import datetime\nfrom sklearn.impute import SimpleImputer\nfrom imblearn.over_sampling import SMOTE, RandomOverSampler\n\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nimport math\nimport pickle\n\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nnltk.download('stopwords')\n\n! pip install pandasql\nfrom pandasql import sqldf","metadata":{"id":"zUvdyfCea-a4","outputId":"15b4294c-46ae-4798-9722-fef492cd2e9b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{"id":"fUF-wg5aa89B"}},{"cell_type":"code","source":"f = open('/content/results.json',)\ndata = json.load(f)\ndf = pd.DataFrame(data)\ndf.head()","metadata":{"id":"sEgT3n_Pa-jF","outputId":"dacd67cb-4e5a-45d2-a408-91d3af309bd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"id":"_-lpxynga_Cz","outputId":"3419688c-eecb-4da4-a6f2-1a5b0f443f02"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('--------')\ndisplay(df.ReviewTitle.unique())\ndisplay(print('Unique values: ', len(df.ReviewTitle.unique())))\n\nprint('--------')\ndisplay(df.URL.unique())\ndisplay(print('Unique values: ', len(df.URL.unique())))\n\nprint('--------')\ndisplay(df.ReviewDetails.unique())\ndisplay(print('Unique values: ', len(df.ReviewDetails.unique())))","metadata":{"id":"0dCTA-4fbXx0","outputId":"5aa0309d-311c-489e-a6d3-de391812ba5f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As we can see, company name is mentioned in the URL & ReviewDetails has Datetime, Employeee type and Location.**\n\n","metadata":{"id":"WZRHSYQW_jz_"}},{"cell_type":"markdown","source":"**We will try to extract them as much as possible.**","metadata":{"id":"cQuQzaPxAHSQ"}},{"cell_type":"markdown","source":"# Extracting and Preprocessing","metadata":{"id":"61udZbRD-GPJ"}},{"cell_type":"markdown","source":"**Extracting Company names**","metadata":{"id":"jVb-c1W3kOlD"}},{"cell_type":"code","source":"# Extracting Company name from URL\ndf['Company'] = df.URL.str.split('/')[:].str[4]","metadata":{"id":"MOXKN_F5cMzG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking unique values in Company\ndisplay(df.Company.unique())\ndisplay(print('Unique values: ', len(df.Company.unique())))","metadata":{"id":"bfeaemL_bX--","outputId":"a9ae9633-3195-42e6-8eec-7edf45c8f20b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Extracting Datetime**","metadata":{"id":"1PoFsvO3kI6o"}},{"cell_type":"code","source":"# Extracting Date & Time from ReviewDetails\ndf['Timestamp'] = df['ReviewDetails'].str.split('-', expand=True)[2]","metadata":{"id":"JsiWllwS1lNm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spliting Year, Month, Day\ndf['Year'] = df['Timestamp'].str.split(',', expand=True)[1]\ndf['Month'] = df['Timestamp'].str.split(',', expand=True)[0].str.split(' ', expand=True)[2]\ndf['Day'] = df['Timestamp'].str.split(',', expand=True)[0].str.split(' ', expand=True)[3]","metadata":{"id":"yZE-xl2i1lGP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking missing values\ndisplay(df['Day'].isnull().sum())\ndisplay(df['Month'].isnull().sum())\ndisplay(df['Year'].isnull().sum())","metadata":{"id":"rKClExwo5W8Z","outputId":"9c23a635-6c89-4008-8a95-370691c21f74"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping missing values\ndf = df.dropna()","metadata":{"id":"LC-t60V_7MC7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing unecessary blank spaces\ndf['Year'] = df['Year'].str.replace(' ', '')","metadata":{"id":"3ePy21x-8ZKy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merging and adding new Datetime column\ntemp_date = df[['Day', 'Month', 'Year']]\ndf['Timestamp'] = pd.to_datetime(temp_date.astype(str).agg('-'.join, axis=1), format='%d-%B-%Y')","metadata":{"id":"1m1J6Kt_hefO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping unecessary columns\ndf.drop(['Year', 'Month', 'Day'], axis=1, inplace=True)","metadata":{"id":"ggaUHy9A8qoT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"48WkhHkgp1bE","outputId":"d770ce44-8f9b-443a-8394-13a34c1fb1dd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Extracting Type of Employee submitted the review**","metadata":{"id":"UsKeWpGhkTqb"}},{"cell_type":"code","source":"# Extract EmployeeType from ReviewDetails\ndf['EmployeeType'] = df['ReviewDetails'].str.split('-', expand=True)[0]","metadata":{"id":"m8DF5Zjw-NXi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking Unique values\ndisplay(df.EmployeeType.unique())\ndisplay(print('Unique values: ', len(df.EmployeeType.unique())))","metadata":{"id":"7oa4ZEx7-nRR","outputId":"b4b62b75-15e2-4a5d-ba27-3fd8b4356a38"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_employee_type(value):\n  return 'Current Employee' if 'Current' in value else 'Former Employee'","metadata":{"id":"tkxvtxP3-NRK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add new column EmployeeTpe\ndf['EmployeeType'] = df.apply(lambda row: get_employee_type(row['EmployeeType']),axis=1)","metadata":{"id":"xjUiMoOL-NUR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"Rp9Fnr_O-NLB","outputId":"37595416-8071-4afa-aee2-3832be4465a8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Extracting Location from Review Details**","metadata":{"id":"XBDjewZtlS2-"}},{"cell_type":"code","source":"df['Location'] = df['ReviewDetails'].str.split('-', expand=True)[1]","metadata":{"id":"W-n2hdeo-NFb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(df.Location.unique())\ndisplay(print('Unique values: ', len(df.Location.unique())))","metadata":{"id":"Xqv84qBu-NCM","outputId":"835efd25-b6dc-42bc-a7be-ca1c919bfd96"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Merging ReviewTitle + CompleteReview, cause not considering will be a waste.**","metadata":{"id":"_r8YpRmulx1e"}},{"cell_type":"code","source":"df['Review'] = df['ReviewTitle'] + ' ' + df['CompleteReview']","metadata":{"id":"LrHkNbs7UEdP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop uneccsary columns\ndf.drop(['ReviewTitle', 'CompleteReview', 'URL', 'ReviewDetails'], axis=1, inplace=True)","metadata":{"id":"0dikMvsXUQNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Location = df.Location.str.strip()\ndf.Location = df.Location.str.lower()","metadata":{"id":"e8CHTRHAmbwA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sqldf(\"\"\"select Location, count(*) from df group by Location order by count(*) desc limit 10\"\"\")","metadata":{"id":"aYKh-MHHm798","outputId":"4a5013b6-e0d4-4c53-b7bf-5e230cbd7d39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Location[df['Location'] == ''] = 'Unknown'","metadata":{"id":"TllKX6Ovnr1n","outputId":"7620d0e2-eeed-4e59-848f-a891249ba88d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Location.unique()","metadata":{"id":"cEQ427ZDmm_U","outputId":"717bd929-6c0e-4e59-84ea-6b8ddf79494a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Locations are entered manually so it os inconsistent and unrealiable. We may not be able to use it until we clean it manually. My Bad**","metadata":{"id":"NUtQYzdysbs-"}},{"cell_type":"markdown","source":"# EDA","metadata":{"id":"MYaMnPJgoXF7"}},{"cell_type":"code","source":"df.describe()","metadata":{"id":"1_pglbdHpELX","outputId":"a928a2d0-4622-49af-e7d5-cf91f4cdc173"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,8))\nsns.countplot(x ='EmployeeType', data = df)\nplt.xticks(rotation=90)","metadata":{"id":"B51a3yCxbYEQ","outputId":"9241ed99-03f6-41a5-9631-04c05e7fd4d8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"EmployeeType seems fairly balanced","metadata":{"id":"vXkpvrMzEL9k"}},{"cell_type":"code","source":"sns.histplot(df['Rating'])","metadata":{"id":"ws69p71wbYG8","outputId":"55560412-a7ed-40af-9d2c-5dda2779fa69"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can see that the dataset is imbalance which can effect the model performance","metadata":{"id":"KyiZ9rvXzwm1"}},{"cell_type":"code","source":"plt.figure(figsize=(8,4))\nsns.countplot(x='Rating', hue='EmployeeType',data=df,palette='viridis')","metadata":{"id":"3yxIkYmrzI9R","outputId":"87c4fa2b-ff26-4b98-f431-6761d09e2530"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20,8))\nsns.countplot(x ='Company', data = df)\nplt.xticks(rotation=90)","metadata":{"id":"XrZnsLa8GCZR","outputId":"3ab77935-d164-4d7f-b8e9-d460671b4c2a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Large number of reviews belongs to TCS, IBM, Accenture, Infosys, HDFC\n","metadata":{"id":"HvqVt-3JEDU8"}},{"cell_type":"markdown","source":"**Rating Distribution for Top 10 Companies (Review Count)**","metadata":{"id":"7_hTO28axW6f"}},{"cell_type":"code","source":"dftop_10 = sqldf(\"\"\"select Company, count(*) from df group by Company order by count(*) desc limit 10\"\"\")\ndftop_10 = sqldf(\"\"\"select * from df where Company in (select Company from dftop_10)\"\"\")","metadata":{"id":"Avu-prqhGCTK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (30,8))\nsns.countplot(x=\"Company\", hue=\"Rating\", data=dftop_10)","metadata":{"id":"zFcTp_3JZ_fK","outputId":"fc55e443-a2b8-4f19-ee1d-1410b5652f93"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Rating Distribution for Bottom 10 Companies (Review Count)**","metadata":{"id":"RbNGhPeVx8PH"}},{"cell_type":"code","source":"dfbot_10 = sqldf(\"\"\"select Company, count(*) from df group by Company order by count(*) asc limit 10\"\"\")\ndfbot_10 = sqldf(\"\"\"select * from df where Company in (select Company from dfbot_10)\"\"\")\ndfbot_10.Rating = pd.to_numeric(dfbot_10.Rating)","metadata":{"id":"dkwCTsJkqqyA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (30,8))\nsns.countplot(x=\"Company\", hue=\"Rating\", data=dfbot_10)","metadata":{"id":"m1GIX5E8Z_iH","outputId":"afbdd0c6-55a1-4e41-d8b7-7c4e7e0fca96"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Timestamp-Rating Analysis**","metadata":{"id":"1CG8zzoBstxH"}},{"cell_type":"code","source":"df_g1 = df\ndf_g1['Year'] = df_g1.Timestamp.astype(str).str[:4]\ndf_g1 = sqldf(\"\"\"select Company, Rating, Year, count(*) as count from df_g1 group by Company, Rating, Year\"\"\")\n\nfor i, company_name in enumerate(list(df.Company.unique())):\n  plt.figure(i)\n  plt.figure(figsize = (10,8))\n  sns.lineplot(x=df_g1.Year, y=\"count\", hue=\"Rating\", data=df_g1[df_g1['Company'] == company_name]).set_title(company_name)","metadata":{"id":"u6bge1f8p9G5","outputId":"169c377e-ac3b-4389-c3d5-026ab470c94c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**For some reason there's a spike in reviews, espacially for 5-4-3 rating stars, during the period 2017-2019**","metadata":{"id":"tI1-GkV31YxV"}},{"cell_type":"markdown","source":"**After 2017-2018, 4 & 5 Star reviews started to fall down for all companies.**","metadata":{"id":"CTUXlOmu16ml"}},{"cell_type":"markdown","source":"# Cleaning","metadata":{"id":"OML0MLbfWDVT"}},{"cell_type":"code","source":"#Dropping unecessary columns\ndf.drop(['Company', 'EmployeeType', 'Timestamp'], axis=1, inplace=True)","metadata":{"id":"0EfLIXN-WJ8L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Coverting 5 ratings in 3 classes\n\n# 0    Positive  (5-4 Stars)\n# 1    Neural    (2-3 Stars)\n# 2    Negative  (1 Stars)\n\ndf.Rating.replace({'1.0': 3, '2.0': 2, '3.0': 2, '4.0': 1, '5.0': 1}, inplace=True)","metadata":{"id":"-B1cJs4ergvO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting Rating field from float to int\ndf.Rating = df.Rating.astype(float).astype(int)","metadata":{"id":"48nB4Ftl-DbU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Selecting Sample","metadata":{"id":"YB6h68k3nPGX"}},{"cell_type":"code","source":"df = df.sample(frac=0.45)","metadata":{"id":"z0NUwkrSnOPc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Over Sampling","metadata":{"id":"5Ynj7RWEfmKu"}},{"cell_type":"code","source":"ros = RandomOverSampler()\nX_sample, y_sample = ros.fit_resample(df[['Review']], df['Rating'])\ndf = pd.concat([pd.DataFrame(X_sample), pd.DataFrame(y_sample)], axis=1)\n\ndf.columns = ['Review', 'Rating']","metadata":{"id":"nfHTF9mFfk_s","outputId":"f9795c1d-b8b5-4f2e-8875-6e5979df249c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build, Train, Test\n","metadata":{"id":"6XCitE-vFXlT"}},{"cell_type":"code","source":"vocab_size = 10000\nsentence_length = 50\nX = df.drop('Rating',axis=1)\ny = df['Rating']\nsentences = X.copy()","metadata":{"id":"ZJWvobz6E96A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Resetting so that we don't get error during extracting process \nsentences.reset_index(inplace=True)","metadata":{"id":"7T-I8eizE9ut"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_corpus(sentences):\n  ps = PorterStemmer()\n  corpus = []\n  for i in range(0, len(sentences)):\n    review = re.sub('[^a-zA-Z]', ' ', sentences['Review'][i]).lower().split()\n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)\n  return corpus","metadata":{"id":"4v3tKXRHE9r1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_ohe(corpus):\n  return [one_hot(words,vocab_size) for words in corpus] ","metadata":{"id":"W9fOuaUvE9jW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_padding(onehot_repr):\n  return pad_sequences(onehot_repr,padding='pre',maxlen=sentence_length)","metadata":{"id":"YbCJg8UN-N4m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating corpus\ncorpus = generate_corpus(sentences)","metadata":{"id":"lcthJpEA6kPF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating \nonehot_repr = convert_ohe(corpus)","metadata":{"id":"ZpcoMEHi9c3M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating word embedding. \nembedded_docs = add_padding(onehot_repr)","metadata":{"id":"1hz5pZ0RE9dN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = pd.get_dummies(df[\"Rating\"])","metadata":{"id":"VuLWWCTO1D-L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LSTM Model\nembedding_vector_features=80\nmodel=Sequential()\nmodel.add(Embedding(vocab_size,embedding_vector_features,input_length=sentence_length))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(3,activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"id":"XXMxfJDaE9XI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nX_final=np.array(embedded_docs)\ny_final=np.array(y)","metadata":{"id":"5hb3RCuAE9Rd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)","metadata":{"id":"vR-sQihRE9Iv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=50,batch_size=64)","metadata":{"id":"jE_bK6SbE9Fy","outputId":"01faa8db-7e25-4824-828c-b7c48c508def"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving model for future use\n# model.save('model.h5')","metadata":{"id":"Uko6H5rs-W-m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation Metrics","metadata":{"id":"Hwnr3DMLZjnS"}},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"id":"ARQfdyPyE8-e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_pred,axis=1))","metadata":{"id":"tQWwNNzs2ROX","outputId":"ae86fb36-e4a5-42fa-e837-7f7fd1010dd3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint('Model Accuracy', accuracy_score(np.argmax(y_test,axis=1),np.argmax(y_pred,axis=1)))","metadata":{"id":"Imc-EC_O2Q3-","outputId":"7b524fa5-165e-49e8-d82d-117ea8463035"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making Prediction","metadata":{"id":"fPydM-m2ctAh"}},{"cell_type":"code","source":"data = pd.DataFrame([{'Review': 'Great place to work. Nice work culture'}, {'Review': 'Very less salary. bad work culture'}, {'Review': 'No fix working hours. Good salary hike'}])","metadata":{"id":"0ciY9SJv_Jly"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus = generate_corpus(data)\nonehot_repr = convert_ohe(corpus)\nembedded_docs = add_padding(onehot_repr)\ny_pred = model.predict(embedded_docs)","metadata":{"id":"V0ytjWtR3wat"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_text = { 0:'Positive', 1:'Neural', 2:'Negative'}","metadata":{"id":"Gy-USByyBOGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.concat([data, pd.DataFrame(np.argmax(y_pred,axis=1), columns=['Prediction']).replace(predict_text)], axis=1)","metadata":{"id":"gSR1Zg_tBSQu","outputId":"d06c3151-b83b-4ede-e21f-661ecb6bb996"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extras","metadata":{"id":"KB8Tn5V3wt2V"}},{"cell_type":"code","source":"# model.save('model.h5')\n\n# from keras.models import load_model\n# model = load_model('model.h5')","metadata":{"id":"FtBMb7sa3wQK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saving corpus for future use\n\n# with open('corpus.pkl', 'wb') as f:\n#   pickle.dump(corpus, f)\n\n# with open('corpus.pkl', 'rb') as f:\n#   corpus = pickle.load(f)","metadata":{"id":"k0n7_tJFyqAO"},"execution_count":null,"outputs":[]}]}